{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALISIS TRACK BASADO EN PWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PASO_1\n",
    "#Importamos un xml procedente de pwd\n",
    "\n",
    "from xml.dom.minidom import parse\n",
    "import xml.dom.minidom\n",
    "import pandas as pd\n",
    "\n",
    "path='Mallorca70.3_tp'\n",
    "DOMTree = xml.dom.minidom.parse(path+\".xml\")\n",
    "\n",
    "\n",
    "collection = DOMTree.documentElement\n",
    "\n",
    "trkpts = collection.getElementsByTagName(\"sample\")\n",
    "list_track = []\n",
    "\n",
    "count=0\n",
    "for trkpt in trkpts:\n",
    "    count +=1\n",
    "    if len(trkpt.getElementsByTagName(\"timeoffset\"))==0:\n",
    "        timeoffset = ''\n",
    "    else:\n",
    "        timeoffset = float(trkpt.getElementsByTagName(\"timeoffset\")[0].firstChild.nodeValue)\n",
    "    \n",
    "    if len(trkpt.getElementsByTagName(\"hr\"))==0:\n",
    "        hr = ''\n",
    "    else:\n",
    "        hr = float(trkpt.getElementsByTagName(\"hr\")[0].firstChild.nodeValue)\n",
    "    \n",
    "    if len(trkpt.getElementsByTagName(\"spd\"))==0:\n",
    "        spd = ''\n",
    "    else:\n",
    "        spd = float(trkpt.getElementsByTagName(\"spd\")[0].firstChild.nodeValue)    \n",
    "    \n",
    "    if len(trkpt.getElementsByTagName(\"pwr\"))==0:\n",
    "        pwr = ''\n",
    "    else:\n",
    "        pwr = float(trkpt.getElementsByTagName(\"pwr\")[0].firstChild.nodeValue)\n",
    "\n",
    "    if len(trkpt.getElementsByTagName(\"cad\"))==0:\n",
    "        cad = ''\n",
    "    else:\n",
    "        cad = float(trkpt.getElementsByTagName(\"cad\")[0].firstChild.nodeValue)\n",
    "\n",
    "    if len(trkpt.getElementsByTagName(\"dist\"))==0:\n",
    "        dist = ''\n",
    "    else:\n",
    "        dist = float(trkpt.getElementsByTagName(\"dist\")[0].firstChild.nodeValue)\n",
    "\n",
    "    if len(trkpt.getElementsByTagName(\"lat\"))==0:\n",
    "        lat = ''\n",
    "    else:\n",
    "        lat = float(trkpt.getElementsByTagName(\"lat\")[0].firstChild.nodeValue)\n",
    "\n",
    "    if len(trkpt.getElementsByTagName(\"lon\"))==0:\n",
    "        lon = ''\n",
    "    else:\n",
    "        lon = float(trkpt.getElementsByTagName(\"lon\")[0].firstChild.nodeValue)\n",
    "\n",
    "    if len(trkpt.getElementsByTagName(\"alt\"))==0:\n",
    "        alt = ''\n",
    "    else:\n",
    "        alt = float(trkpt.getElementsByTagName(\"alt\")[0].firstChild.nodeValue)    \n",
    "\n",
    "    if len(trkpt.getElementsByTagName(\"temp\"))==0:\n",
    "        temp = ''\n",
    "    else:\n",
    "        temp = float(trkpt.getElementsByTagName(\"temp\")[0].firstChild.nodeValue)\n",
    "   \n",
    "    list_track.append([timeoffset, hr, spd, pwr, cad, dist, lat, lon, alt, temp])\n",
    "\n",
    "print (\"Puntos cargados: %d\" %count)\n",
    "\n",
    "    \n",
    "\n",
    "result = pd.DataFrame(list_track)\n",
    "result.columns=[\"timeoffset\", \"hr\", \"spd\", \"pwr\", \"cad\", \"dist\", \"lat\", \"lon\", \"alt\", \"temp\"]\n",
    "result['prueba'] = path\n",
    "result.to_excel('Intermedio'+path+'.xlsx')\n",
    "result.to_excel(path+\".xlsx\")\n",
    "print('finish')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALISIS TRACK BASADO EN GPX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO_1\n",
    "#Importamos un xml procedente de gpx\n",
    "\n",
    "from xml.dom.minidom import parse\n",
    "import xml.dom.minidom\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#path='Analisis_Aerodinamica'\n",
    "#path='Entreno_preparatorio'\n",
    "#path='2017_05_13_Triatlón'\n",
    "path='20180406_LEVS_195_90_R_E'\n",
    "DOMTree = xml.dom.minidom.parse(path+\".xml\")\n",
    "\n",
    "collection = DOMTree.documentElement\n",
    "\n",
    "trkpts = collection.getElementsByTagName(\"trkpt\")\n",
    "list_track = []\n",
    "\n",
    "def to_dt(dato):\n",
    "    t=pd.to_datetime(dato)\n",
    "    return t.hour*3600+t.minute*60+t.second\n",
    "\n",
    "count=0\n",
    "\n",
    "for trkpt in trkpts:\n",
    "    count +=1\n",
    "    if trkpt.hasAttribute(\"lat\"):\n",
    "      lat = float(trkpt.getAttribute(\"lat\"))\n",
    "    if trkpt.hasAttribute(\"lon\"):\n",
    "      lon = float(trkpt.getAttribute(\"lon\"))\n",
    "    \n",
    "    if len(trkpt.getElementsByTagName(\"ele\"))==0:\n",
    "        alt = ''\n",
    "    else:\n",
    "        alt = float(trkpt.getElementsByTagName(\"ele\")[0].firstChild.nodeValue)\n",
    "    \n",
    "    if len(trkpt.getElementsByTagName(\"time\"))==0:\n",
    "        time = ''\n",
    "    else:\n",
    "        time = trkpt.getElementsByTagName(\"time\")[0].firstChild.nodeValue\n",
    "    \n",
    "    if len(trkpt.getElementsByTagName(\"gpxdata:hr\"))==0:\n",
    "        hr = ''\n",
    "    else:\n",
    "        hr = float(trkpt.getElementsByTagName(\"gpxdata:hr\")[0].firstChild.nodeValue)\n",
    "    \n",
    "    if len(trkpt.getElementsByTagName(\"gpxdata:cadence\"))==0:\n",
    "        cad = ''\n",
    "    else:\n",
    "        cad = float(trkpt.getElementsByTagName(\"gpxdata:cadence\")[0].firstChild.nodeValue)\n",
    "        \n",
    "    if len(trkpt.getElementsByTagName(\"gpxdata:temp\"))==0:\n",
    "        temp = ''\n",
    "    else:\n",
    "        temp = float(trkpt.getElementsByTagName(\"gpxdata:temp\")[0].firstChild.nodeValue)\n",
    "    \n",
    "    if len(trkpt.getElementsByTagName(\"gpxdata:distance\"))==0:\n",
    "        dist = ''\n",
    "    else:\n",
    "        dist = float(trkpt.getElementsByTagName(\"gpxdata:distance\")[0].firstChild.nodeValue)\n",
    "    \n",
    "    if len(trkpt.getElementsByTagName(\"gpxdata:power\"))==0:\n",
    "        pwr = ''\n",
    "    else:\n",
    "        pwr = float(trkpt.getElementsByTagName(\"gpxdata:power\")[0].firstChild.nodeValue)\n",
    "\n",
    "    if len(trkpt.getElementsByTagName(\"gpxdata:speed\"))==0:\n",
    "        spd = ''\n",
    "    else:\n",
    "        spd = float(trkpt.getElementsByTagName(\"gpxdata:speed\")[0].firstChild.nodeValue)\n",
    "    \n",
    "    timeoffset = to_dt(time)\n",
    "    \n",
    "    list_track.append([timeoffset, hr, spd, pwr, cad, dist, lat, lon, alt, temp])\n",
    "\n",
    "result = pd.DataFrame(list_track)\n",
    "result.columns = [\"timeoffset\", \"hr\", \"spd\", \"pwr\", \"cad\", \"dist\", \"lat\", \"lon\", \"alt\", \"temp\"]\n",
    "result['prueba'] = path\n",
    "print (\"Puntos cargados: %d\" %count)\n",
    "result.to_excel('Intermedio'+path+'.xlsx')\n",
    "print('finish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#conda install -c conda-forge geopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENRIQUECEMOS EL FICHERO. COMUN PARA TODOS LOS ORIGENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math as mt\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sync_bearing(ori_bearing):\n",
    "    if ori_bearing < -90:\n",
    "        new_bearing = 450+ori_bearing\n",
    "    else:\n",
    "        new_bearing = ori_bearing+90\n",
    "    return new_bearing\n",
    "\n",
    "def deteccion_tramos(input_df):\n",
    "    tramos = [0]\n",
    "    tramo = 0\n",
    "    pendiente = 0\n",
    "    pendiente_ant = 0\n",
    "\n",
    "    tramos_100 = [0]\n",
    "    tramo100 = 0\n",
    "    acum_dist = 0\n",
    "        \n",
    "\n",
    "    lista_tramos = [(0,0,\"Inicio\")]\n",
    "\n",
    "    lista_tramos_2 = []\n",
    "    tramo_inicial = 0\n",
    "    power_acum = 0\n",
    "    \n",
    "    i = 1\n",
    "    input_df.iloc[0,5] = 0\n",
    "    \n",
    "    \n",
    "    print(\"Entramos en el While1 %d\" % len(input_df.index))\n",
    "    while i < len(input_df.index):\n",
    "        \n",
    "        \n",
    "        power_acum = power_acum + (input_df.iloc[i][\"pwr\"]*(input_df.iloc[i][\"timeoffset\"]-input_df.iloc[i-1][\"timeoffset\"]))\n",
    "        \n",
    "        #Calculo de tramos continuos\n",
    "        \n",
    "        #print(\"punto = %d y tramo = %d\" % (i, tramo))\n",
    "        pendiente = input_df.iloc[i][\"new_ele\"]-input_df.iloc[i-1][\"new_ele\"]\n",
    "\n",
    "        if pendiente * pendiente_ant >=0:\n",
    "            tramos.append(tramo)\n",
    "        else:\n",
    "            #Cada tramo en 1 línea\n",
    "            distancia_tramo = input_df.iloc[i-1][\"dist\"]-input_df.iloc[tramo_inicial][\"dist\"]\n",
    "            tiempo_tramo = input_df.iloc[i-1][\"timeoffset\"]-input_df.iloc[tramo_inicial][\"timeoffset\"]\n",
    "            desnivel_tramo = input_df.iloc[i-1][\"new_ele\"]-input_df.iloc[tramo_inicial][\"new_ele\"]\n",
    "            porcent_des = desnivel_tramo/distancia_tramo*100\n",
    "            sp_pwd = power_acum/tiempo_tramo\n",
    "            vel_calc = (distancia_tramo/tiempo_tramo)*3.6\n",
    "            lista_tramos_2.append((tramo, tramo_inicial, i-1,sp_pwd,tiempo_tramo,distancia_tramo,vel_calc,porcent_des))\n",
    "            \n",
    "            power_acum = 0\n",
    "            \n",
    "            #Cada Inicio o Fin de tramo en 1 línea\n",
    "            tramo_inicial = i\n",
    "            lista_tramos.append((tramo,i-1,\"Fin\"))\n",
    "            tramo +=1\n",
    "            tramos.append(tramo)\n",
    "            lista_tramos.append((tramo,i,\"Inicio\"))\n",
    "            \n",
    "        pendiente_ant = pendiente            \n",
    "        \n",
    "        #Calculo de tramos de 100m\n",
    "        acum_dist = input_df.iloc[i-1][\"dist\"]\n",
    "        tramo100 = mt.floor(acum_dist/100)\n",
    "        tramos_100.append(tramo100)\n",
    "        \n",
    "        i +=1\n",
    "          \n",
    "\n",
    "\n",
    "    print(\"tramos : %d continuos y %d de 100m\" % (len(set(tramos)), len(set(tramos_100))))\n",
    "    print(\"Salimos del While\")\n",
    "   \n",
    "\n",
    "\n",
    "    return lista_tramos_2, lista_tramos, tramos, tramos_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#path='Analisis_Aerodinamica'\n",
    "#path='Entreno_preparatorio'\n",
    "#path='2017_05_13_Triatlón'\n",
    "path='20180406_LEVS_195_90_R_E'\n",
    "\n",
    "df = pd.read_excel('Intermedio'+path+'.xlsx')\n",
    "\n",
    "df2 = df[df['lat'] >0]\n",
    "df2['pwr'].fillna(0, inplace=True)\n",
    "#df2.drop(['dist','cad','hr','spd'], axis=1, inplace=True)\n",
    "\n",
    "from geopy.distance import distance\n",
    "from geopy import Point\n",
    "i=1\n",
    "dist_c=[]\n",
    "dist_c.append(0)\n",
    "ele_gain = []\n",
    "ele_gain.append(0)\n",
    "d=0\n",
    "e=0\n",
    "porc=[]\n",
    "porc.append(0)\n",
    "spd_c=[]\n",
    "spd_c.append(0)\n",
    "spd_prev=[]\n",
    "spd_prev.append(0)\n",
    "ele_prev=[]\n",
    "ele_prev.append(0)\n",
    "bearing=[]\n",
    "bearing.append(0)\n",
    "timeoffset_prev=[]\n",
    "timeoffset_prev.append(0)\n",
    "\n",
    "ini_timeoffset = df2.iloc[0]['timeoffset']\n",
    "time=[]\n",
    "time.append(0)\n",
    "\n",
    "\n",
    "while i < len(df2):\n",
    "    #print(\"Punto %d\" %i\n",
    "    punto1 = Point(df2.iloc[i-1]['lon'], df2.iloc[i-1]['lat'])\n",
    "    punto2 = Point(df2.iloc[i]['lon'], df2.iloc[i]['lat'])\n",
    "    time.append(df2.iloc[i]['timeoffset']-ini_timeoffset)\n",
    "    dist_c.append(distance(punto1, punto2).m)\n",
    "    d = distance(punto1, punto2).m\n",
    "    spd_c.append(float(d/(df2.iloc[i]['timeoffset']-df2.iloc[i-1]['timeoffset'])))\n",
    "    punto1 = df2.iloc[i-1]['alt']\n",
    "    punto2 = df2.iloc[i]['alt']\n",
    "    ele_gain.append((punto2)-(punto1))\n",
    "    e = punto2-punto1\n",
    "    porc.append(e*100/d)\n",
    "    lona = df2.iloc[i-1]['lon']\n",
    "    lata = df2.iloc[i-1]['lat']\n",
    "    lonb = df2.iloc[i]['lon']\n",
    "    latb = df2.iloc[i]['lat']\n",
    "    X = mt.cos(lonb)*mt.sin(latb-lata)\n",
    "    Y = mt.cos(lona)*mt.sin(lonb)-mt.sin(lona)*mt.cos(lonb)*mt.cos(latb-lata)\n",
    "    \n",
    "    #bearing.append(mt.atan2(X,Y)*57.2957795)  Se modifica por la siguiente línea que corrige estandariza el ángulo\n",
    "    bearing.append(sync_bearing(mt.atan2(X,Y)*57.2957795))\n",
    "    \n",
    "    i+=1\n",
    "df2['dist_c']=dist_c\n",
    "df2['ele_gain']=ele_gain\n",
    "df2['porc']=porc\n",
    "df2['spd_c']=spd_c\n",
    "df2['bearing']=bearing\n",
    "i=1\n",
    "while i < len(df2):\n",
    "    spd_prev.append(df2.iloc[i-1]['spd_c'])\n",
    "    ele_prev.append(df2.iloc[i-1]['alt'])\n",
    "    timeoffset_prev.append(df2.iloc[i-1]['timeoffset'])\n",
    "    i+=1\n",
    "df2['spd_prev']=spd_prev\n",
    "df2['ele_prev']=ele_prev\n",
    "df2['timeoffset_prev']=timeoffset_prev\n",
    "\n",
    "#aplicamos el suavizado de señal\n",
    "axis_y = df[\"alt\"]\n",
    "axis_yhat = savgol_filter(axis_y, 31, 2)\n",
    "df2[\"new_ele\"] = axis_yhat\n",
    "df2[\"time_seg\"] = time\n",
    "\n",
    "df2[\"tramo\"] = tramos\n",
    "df2[\"tramos_100\"] = tramos_100\n",
    "\n",
    "\n",
    "# lista_tramos_2, lista_tramos, tramos, tramos_100 = deteccion_tramos(df2)\n",
    "\n",
    "#path='20180406_LEVS_195_90_R_E'\n",
    "\n",
    "\n",
    "#df2.to_excel(path+'_ml.xlsx')\n",
    "\n",
    "print('finish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2[0:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_tramos_2, lista_tramos, tramos, tramos_100 = deteccion_tramos(df2)\n",
    "#tramo, tramo_inicial, tramo_final,pwd,tiempo_tramo,distancia_tramo,vel_calc,porcent_des\n",
    "result = pd.DataFrame(lista_tramos_2)\n",
    "result.columns= [\"tramo\", \"tramo_inicial\", \"tramo_final\",\"sp_pwd\",\"tiempo_tramo\",\"distancia_tramo\",\"vel_calc\",\"porcent_des\"]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#AÑADIMOS NUEVAS VARIABLES DEPENDIENTES DE LA RUTA Y EL CICLISTA\n",
    "#altura = path.split('_')[2]\n",
    "#peso = path.split('_')[3]\n",
    "#tpo_bici = path.split('_')[4]\n",
    "#tpo_entreno = path.split('_')[5]\n",
    "\n",
    "df2['altura'] = path.split('_')[2]\n",
    "df2['peso'] = path.split('_')[3]\n",
    "df2['tpo_bici'] = path.split('_')[4]\n",
    "df2['tpo_entreno'] = path.split('_')[5] \n",
    "\n",
    "df2.to_csv(path+'_ml.csv')\n",
    "print('finish')\n",
    "#print(altura,peso,tpo_bici,tpo_entreno)\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lista_tramos_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
